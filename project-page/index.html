<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="GV-Bench: Benchmarking Local Feature Matching for Geometric Verification of Long-term Loop Closure Detection">
  <meta property="og:title" content="GV-Bench"/>
  <meta property="og:description" content="GV-Bench: Benchmarking Local Feature Matching for Geometric Verification of Long-term Loop Closure Detection"/>
  <meta property="og:url" content="https://jingwenyust.github.io/GV-Bench"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/radar-webpage.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/image/radar-webpage.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>GV-Bench Project Page</title>
  <link rel="icon" type="image/x-icon" href="static/images/ust-blue.jpeg">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">GV-Bench: Benchmarking Local Feature Matching for Geometric Verification of Long-term Loop Closure Detection</h1>
            <!-- <h2 class="is-size-3">IROS 2024</h2> -->
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://jingwenyust.github.io/" target="_blank">Jingwen Yu</a><sup>1,2</sup>,</span>
                <span class="author-block">
                  <a href="https://medlartea.github.io/" target="_blank">Hanjing Ye</a><sup>2</sup>,</span>
                  <span class="author-block">
                    <a href="https://gogojjh.github.io/" target="_blank">Jianhao Jiao</a><sup>3</sup>,</span>
                  <span class="author-block">
                    <a href="https://ece.hkust.edu.hk/pingtan" target="_blank">Ping Tan</a><sup>1</sup>,</span>
                  <span class="author-block">
                    <a href="https://scholar.google.com/citations?user=J7UkpAIAAAAJ&hl=en" target="_blank">Hong Zhang</a><sup>2,*</sup>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">
                      <sup><small>1 </small></sup>Hong Kong University of Science and Technology (HKUST) <br/>
                      <sup><small>2 </small></sup>Southern University of Science and Technology (SUSTech) <br/>
                      <sup><small>3 </small></sup>University College London (UCL)<br />
                      IROS 2024</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Corresponding Author</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv link -->
                        <span class="link-block">
                        <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="ai ai-arxiv"></i>
                        </span>
                        <span>arXiv</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link
                    <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/jarvisyjw/GV-Bench" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- chinese intro from wechat -->
                <span class="link-block">
                  <a href="https://mp.weixin.qq.com/s/edUw7vLep0zmve0Uj3IzkQ" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-weixin"></i>
                  </span>
                  <span>中文介绍（by 3D视觉之心）</span>
                </a>
              </span>

                <!-- ArXiv abstract Link -->
                <!-- <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser Image-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
        <img style="display: block; margin-left: auto; margin-right: auto;" src="static/images/radar-webpage.png" alt="MY ALT TEXT" />
      </div>
  </div>
</section>
<!-- End teaser Image -->

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">TL;DR</h2>
        <div class="content has-text-justified">
          <p>
            This paper proposes a unified benchmark targeting geometric verification of loop closure detection under long-term conditional variations. We evaluate six representative local feature matching methods (handcrafted and learning-based) under the benchmark, with in-depth analysis for limitations and future directions.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section hero is-small">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-4">Contributions</h2>
        <div class="content has-text-justified">
          <ol>
            <li>
              <strong>Fair and accessible geometric verification evaluation.</strong>
              We open-source an out-of-box framework with a modular design as illustrated in Fig. 3, allowing for evaluating newly proposed methods on the common ground and extending to more diverse datasets.
            </li>
            <li>
              <strong>A systematic analysis of geometric verification.</strong> By employing the proposed benchmark, we point out possible future directions (e.g., training feature extractor and matcher with conditional variation data) through extensive experiments.
            </li>
          </ol>
        </div>

        <h2 class="title is-4">Key Insight</h2>
        <div class="content has-text-justified">
          <p>
            <strong>All methods suffer from illumination variations and perceptual aliasing.</strong>
            In order to improve the robustness of geometric verification, several potentally effective strategies are proposed:
            <ol>
              <li>
              Training feature extractor and matcher with conditional variation data.
              </li>
              <li>
                Building a multi-condition image database.
              </li>
              <li>
                Exploiting more powerful outlier rejection.
              </li>
            </ol>
            Detailed analysis can be found in the paper, Section IV D. Discussion. Besides, we provide further experiments on false positive analysis in the <a href="https://arxiv.org/abs/2407.11736">supplementary material</a>. The benchmark will be keep updated and extending to other loop closure verification methods (Contributions are welcome and appreciated!).
          </p>
          <!-- <img style="display: block; margin-left: auto; margin-right: auto;" src="static/images/dataset-pipeline.png" alt="MY ALT TEXT" /> -->
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Visual loop closure detection is an important module in visual simultaneous localization and mapping (SLAM), which associates current camera observation with previously visited places. Loop closures correct drifts in trajectory estimation to build a globally consistent map. However, a false loop closure can be fatal, so verification is required as an additional step to ensure robustness by rejecting the false positive loops. Geometric verification has been a well-acknowledged solution that leverages spatial clues provided by local feature matching to find true positives. Existing feature matching methods focus on homography and pose estimation in long-term visual localization, lacking references for geometric verification. To fill the gap, this paper proposes a unified benchmark targeting geometric verification of loop closure detection under long-term conditional variations. Furthermore, we evaluate six representative local feature matching methods (handcrafted and learning-based) under the benchmark, with in-depth analysis for limitations and future directions.          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section hero is-small">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Geometric Verification</h2>
        <div class="content has-text-justified">
        <p>
          Loop Closure Detection consists of two stages: retrieval and verification. Potential loop closure pairs {q<sub>i</sub> , c<sub>i,j</sub> } detected by the retrieval stage are sent for verification. Each pair of images is examined under geometric constraints provided by local feature matching. RANSAC filters the matched correspondences to find the best inliers, which is used as the probability in binary classification.
        </p>
      <img style="display: block; margin-left: auto; margin-right: auto; width: 70%" src="static/images/LCD.png" alt="MY ALT TEXT" />
      </div>

      <h2 class="title is-3">Benchmark Introduction</h2>
        <div class="content has-text-justified">
          <p> <strong>The pipeline of open-sourced benchmark consists of: </strong> 
            <ol>
              <li>Pre-process dataset,</li>
              <li>Randomly select query set (if the dataset does not provide it),</li>
              <li>Retrieve verification candidates for each query,</li>
              <li>Match queries with candidates.</li>
            </ol>
            The dashed modules (Datasets, Retrieval Methods, and Local Feature Matching) are expendable in the open-sourced framework, enabling easy customization for research purposes (i.e., enlarging sequences, using other retrieval methods, and evaluating new feature matching methods.)
          </p>
        <img style="display: block; margin-left: auto; margin-right: auto; width: 70%" src="static/images/dataset-pipeline.png" alt="MY ALT TEXT" />
      </div>

      <h2 class="title is-4">Benchmark Sequences</h2>
        <div class="content has-text-justified">
          <p>
            The benchmark consists of six sequences covering mainly three types of conditional changes: illumination (Night and UAcampus), seasonal (Season and Nordland), and weather changes in long-term loop closure detection. The “Day” sequence serves as the baseline challenge with moderate environmental changes over a short period.
          </p>
        <img style="display: block; margin-left: auto; margin-right: auto; width: 70%" src="static/images/sequences.png" alt="MY ALT TEXT" />
      </div>

      <h2 class="title is-4">Matching Methods</h2>
        <div class="content has-text-justified">
        <img style="display: block; margin-left: auto; margin-right: auto; width: 70%" src="static/images/matching-methods.png" alt="MY ALT TEXT" />
      </div>

    </div>
  </section>

  <section class="section hero is-small">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
      <h2 class="title is-3">Experiment Results</h2>
        <div class="content has-text-justified">
        <p>
          In the proposed benchmark, we use two metrics for evaluation: <strong>maximum recall @100 precision (MR)</strong> and <strong>average precision (AP)</strong>. The MR represents the highest recall while keeping the precision to 100%, representing the ability to find true loop closures without false positives.
        </p>
      </div>
    </div>
    </div>
    </div>
  </section>

  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <img src="static/images/exp_table.png" alt="MY ALT TEXT" />
      </div>
    </div>
  </section>

  <section class="section hero is-small">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <div class="content has-text-justified">
        <img style="display: block; margin-left: auto; margin-right: auto; width: 60%" src="static/images/pr_curve_day.png" alt="MY ALT TEXT" />
        <figcaption>Precision-recall curve</strong> of the “Day” sequence. The marker annotates the maximum recall @100 precision (MR). The area under the curve (AUC) represents average precision (AP).</p>
      </div>
        <h2 class="title is-4">Feature Matching Examples</h2>
        <div class="content has-text-justified">
          In the figures below, we visualize LoFTR matches with vanilla RANSAC. The inliers (green lines) and outliers (red lines) are highlighted. The number of inliers of (c) and (d) are counter-intuitive because RANSAC fails when false matches are dominant (more detailed analysis are provided in Sec. IV-D of the paper).
        </div>
          <figure>
        <img style="display: block; margin-left: auto; margin-right: auto; width: 80%" src="static/images/matching-0.jpg" alt="MY ALT TEXT" />
        <figcaption> (a) Negative pair in “Nordland” with inliers: 9
        </figcaption>
      </figure>
      <figure>
          <img style="display: block; margin-left: auto; margin-right: auto; width: 80%" src="static/images/matching-1.jpg" alt="MY ALT TEXT" />
        <figcaption> (b) Positive pair in “Nordland” with inliers: 37</figcaption>
      </figure>
      <figure>
          <img style="display: block; margin-left: auto; margin-right: auto; width: 80%" src="static/images/robotcar-0.jpg" alt="MY ALT TEXT" />
          <figcaption> (c) Negative pair in “Day” with inliers: 45 </figcaption>
      </figure>
      <figure>
        <img style="display: block; margin-left: auto; margin-right: auto; width: 80%" src="static/images/robotcar-1.jpg" alt="MY ALT TEXT" />
          <figcaption> (d) Positive pair in “Day” with inliers: 41 </figcaption>
      </figure>
        </div>  
      </div>
      
      

      
      </div>
    </div>
  </div>
</section>


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
        @article{yu2024gv,
        title={GV-Bench: Benchmarking Local Feature Matching for Geometric Verification of Long-term Loop Closure Detection},
        author={Yu, Jingwen and Ye, Hanjing and Jiao, Jianhao and Tan, Ping and Zhang, Hong},
        journal={arXiv preprint arXiv:2407.11736},
        year={2024}}
    </code></pre>
    </div>
</section>
<!--End BibTex citation -->


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
